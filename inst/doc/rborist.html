<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>The Rborist package</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">The Rborist package</h1>
<h4 class="date">‘r Sys.Date()’</h4>



<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>The <strong>Rborist</strong> package implements the Random Forest
(TM) algorithm, with particular emphasis on high performance. The
package is an <strong>R</strong>-language spinoff of the
<strong>Arborist</strong> project, a multi-language effort targeting a
variety of decision-tree methods. Look and feel owes a large debt to
Liaw’s original <strong>randomForest</strong> package.</p>
<div id="high-performance" class="section level2">
<h2>High performance</h2>
<p>The interpretation of the phrase “high performance” will vary among
users. We claim that the <strong>Rborist</strong> is a high-performance
package primarily because it either does, or has the potential to, take
advantage of the acceleration offerred by commodity parallel hardware.
We also expect performance to scale in accordance with algorithmic
complexity, decaying gracefully as resource limitations are
approached.</p>
<p>Particular attention has been paid to minimizing data movement and,
especially, toward maximizing <em>data locality</em>. We believe that
this has been a key contributing factor to performance and scalability
and will continue to play a major role in efforts to extend support more
broadly.</p>
<p>The current implementation is limited to in-memory execution on
multicore and multi-socket hardware. We envision the following
improvements in the near to medium term:</p>
<ul>
<li><p>Separate training of tree blocks over multiple compute
nodes.</p></li>
<li><p>Training of significant portions of individual trees on vector
coprocessors, such as GPUs.</p></li>
<li><p>Pipelined training over out-of-memory workloads.</p></li>
</ul>
</div>
</div>
<div id="training-and-validation" class="section level1">
<h1>Training and validation</h1>
<div id="simple-example" class="section level2">
<h2>Simple example</h2>
<p>The simplest way to invoke the package is to pass it a design matrix
and response vector, of conforming dimensions. For appropriately typed
design <em>x</em> and response <em>y</em>, then, it suffices to
call:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>  rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y)</span></code></pre></div>
<p>The design can be either a <em>data.frame</em>, a numeric matrix or
an integer matrix. In the case of a frame, the columns (predictors)
must, individually, have either numeric or factor value. Integer
matrices are coerced internally to their numeric counterparts. The
response type may be either numeric, yielding a regression forest, or
categorical, yielding a classification forest.</p>
<p>The return value (here <em>rs</em>) is of class <em>Rborist</em>. The
full layout of an <em>Rborist</em> object is described by the
<strong>help()</strong> files. A very useful example is the
<em>validation</em> object, which summarizes testing on the out-of-bag
samples.</p>
</div>
<div id="validation" class="section level2">
<h2>Validation</h2>
<div id="regression" class="section level3">
<h3>Regression</h3>
<p>In regression training, the <em>validation</em> object’s members
include mean absolute and square errors, as well as the r-squared
statistic. Continuing from the previous codelet, these are obtainable as
follows:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>  rs<span class="sc">$</span>validation<span class="sc">$</span>mae</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  rs<span class="sc">$</span>validation<span class="sc">$</span>mse</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  rs<span class="sc">$</span>validation<span class="sc">$</span>rsq</span></code></pre></div>
<p>These statistics are derived from the original training reponse
(<em>y</em>, above) and the derived out-of-bag reponse. The out-of-bag
response itself can also be obtained fromt the <em>validation</em>
object:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>   rs<span class="sc">$</span>validation<span class="sc">$</span>yPred</span></code></pre></div>
<p><em>validation</em> also contains member <em>qPred</em>, for use with
quantile regression. This member will be described in the next
section.</p>
</div>
<div id="classification" class="section level3">
<h3>Classification</h3>
<p>In classification training, the <em>validation</em> object also
presents the out-of-bag response in member <em>yPred</em>. Its other
members, however, are specialized for classification:</p>
<ul>
<li><p>The misprediction rate is reported for each classification
category by field <em>mispredition</em>.</p></li>
<li><p>A confusion matrix is reported by field
<em>confusion</em>.</p></li>
<li><p>The out-of-bag error rate is given by <em>oobError</em>.</p></li>
<li><p>The <em>census</em> field is a matrix giving, for each row, the
number of times each response category is predicted for the
row.</p></li>
<li><p>The <em>prob</em> field reports a normalized version of
<em>census</em> and can be interpreted as the probability of predicting
a given category at a given row.</p></li>
</ul>
<p>In addition to <em>validation</em>, an <em>Rborist</em> object
contains several other members. Most of these are used to coordinate
subsequent operations, such as prediction or feature contribution, and
do not directly convey summary information. An exception is the
<em>training</em> member, which summarizes training statistics not
directly related to validation. <em>training</em> currently has a single
member, <em>info</em>:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>       rs<span class="sc">$</span>training<span class="sc">$</span>info</span></code></pre></div>
<p>For each predictor the <em>info</em> vector reports the sum, over all
tree nodes in the forest for which the predictor defines a splitting
condition, of the information value precipitating the respective split.
Although these values depend on the information metric employed, they do
provide a relative measure of each predictor’s importance in the
model.</p>
<p>Validation can be suppressed as follows:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">noValidate =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>This option is primarily for the use of package maintainers, but may
prove useful, for example, in instances when model fit is not a main
concern. The <em>validation</em> field will then have value NULL.</p>
</div>
</div>
</div>
<div id="quantile-prediction" class="section level1">
<h1>Quantile prediction</h1>
<p>When predicting over a regression forest, Rborist provides quantiles
simply for the asking. Leaf information, by default, is rich enough to
make their computation quite easy. Quantiles can be requested in either
of two ways. The simplest is to set option <em>quantiles</em> to
<em>TRUE</em>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">quantiles =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>This default quantile vector consists of quartiles, which are given
by the <em>qPred</em> member mentioned above:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>       rs<span class="sc">$</span>validation<span class="sc">$</span>qPred</span></code></pre></div>
<p>Quantile prediction also estimates the quantile position at which the
predicted mean, <em>yPred</em>, lies. This estimate is reported by the
<em>qEst</em> value, as follow:</p>
<p>’’‘{r, eval = FALSE} rs<span class="math inline">\(validation\)</span>qEst’’’</p>
<p>Explicity specfiying the quantile vector, <em>quantVec</em>, yields
quantiles of any desired type. Deciles, for example, can be requested as
follows:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">quantVec =</span> <span class="fu">seq</span>(<span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="at">by=</span><span class="fl">0.1</span>))</span></code></pre></div>
<p>The algorithm employed to compute the quantiles is approximate, as
bining is employed to improve performance.</p>
<p>If, on the other hand, when training a regression forest, quantiles
are not desired and it is intended that quantiles will not subsequently
be requested <em>after</em> training, space can be saved by representing
leaves in a sparser form:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">thinLeaves=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<div id="tree-and-forest-size" class="section level2">
<h2>Tree and forest size</h2>
<p>The simplest way to affect forest size is to specify the number of
trees. The following codelet requests 100 trees:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">nTree=</span><span class="dv">100</span>)</span></code></pre></div>
<p>This also affects training time, which is expected to scale linearly
with the number of trees.</p>
<p>Training of individual trees can be constrained according to several
parameters. The <em>minNode</em> option places a lower bound on node
sizes, i.e., the number of distinct samples subsumed by each node. A
value of 1, for example, allows splitting to proceed until purity. A
larger value results in a smaller tree, as well as faster training. To
ensure that splitting does not proceed below a node size of 20, for
example:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">minNode=</span><span class="dv">20</span>)</span></code></pre></div>
<p>Another way to control tree size is to specify its maximal depth. The
option <em>nLevel</em> sets an upper bound on the number of levels over
which trees can be trained. The following codelet causes tree
construction to halt after the root is created, resulting in a forest of
singleton trees.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">nLevel =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>As with several other size-based constraints, constraining level
depth also results in faster execution.</p>
<p>Option <em>maxLeaf</em> limits the number of leaves (terminals)
present in a tree. Unlike other size constraints described so far,
<em>maxLeaf</em> is enforced <em>after</em> training, so as not to bias
tree shape. While this pruning operation is quite fast, then, limiting
the number of leaves will not speed the training process.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">maxLeaf =</span> <span class="dv">13</span><span class="er">}</span></span></code></pre></div>
<p>Option <em>minInfo</em> sets a splitting threshold based on relative
information gain. A splitting candidate is rejected if the ratio of
information content between a node and its potential successors lies
below the threshold.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">minRatio =</span> <span class="fl">0.1</span>)</span></code></pre></div>
<p>This option should be applied with care and should probably be
avoided at low predictor count.</p>
<p>Performance as well as storage economy can in some cases both be
enhanced by abstracting away repeated instances of the same predictor
value. This is the idea behind sparse representations and, in
particular, one-hot encodings, in which repeated values of zero are
represented implicitly. The Arborist employs a simlilar strategy, but on
a <em>per-predictor</em> basis, representing high-frequency observations
of a given predictor implicitly. A plurality threshold above which to
compress repeated values is specified by the <em>autoCompress</em>
option:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">autoCompress =</span> <span class="fl">0.4</span>)</span></code></pre></div>
<p>As <em>autoCompress</em> specifies a plurality threshold, only a
single set of repeated values undergoes compression for a given
predictor. Resolution of ties, in particular, is
implementation-dependent. A threshold frequency of 1.0, the maximum,
ensures that no compression takes place, while a threshold frequency of
0.0, the minimum, ensures some value is compressed for each predictor,
regardless of frequency.</p>
<p>As a complement to the <em>thinLeaves</em> option for training, the
<em>Streamline</em> command can be applied following training to reduce
a forest’s memory footprint. <em>Streamline</em> clears fields employed
by validation, quantile regression and feature contribution, so should
not be employed if any of these operations are expected to be performed
subsequently.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>       ...</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Streamline</span>(rs)</span></code></pre></div>
</div>
<div id="sampling-options" class="section level2">
<h2>Sampling options</h2>
<p>Several options affect the behavior of the various sampling mechanims
used by the package.</p>
<p>Option <em>nSamp</em> dictates the number of bagged samples defining
the root of each tree. A smaller sample count may result in smaller
trees, as fewer opportunites arise to split.</p>
<p>Option <em>withRepl</em> specifies whether bag sampling is to be done
with replacement.</p>
<p>Vector <em>rowWeight</em> weights the probability of bagging a given
row. The following invocation gives each row identical weight, which is
also the default behavior:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">rowWeight =</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">/</span><span class="fu">nrow</span>(y), <span class="fu">nrow</span>(y))</span></code></pre></div>
<p>Vector <em>predWeight</em> weights the probability of selecting a
given predictor as splitting candidate. For example, this invocation
selects predictor 0 half as often, per predictor, as the remaining
predictors:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">predWeight =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fu">rep</span>(<span class="fl">1.0</span>, <span class="fu">ncol</span>(x)<span class="sc">-</span><span class="dv">1</span>)))</span></code></pre></div>
<p>Option <em>predProb</em> is the uniform probability of selecting a
predictor for splitting. That is, the value applies uniformly to all
predictors. Hence the number of predictors tried at a given split will
have a binomial distribution.</p>
<p>Option <em>predFixed</em> is the actual number of predictors to test
for a given split, and so calls for sampling predictors without
replacement. <em>predFixed</em> and <em>predProb</em> cannot both be
specified within a single training operation.</p>
<p>For regression training, vector <em>regMono</em> specifies a (signed)
rejection probability to enforce monotonicity with respect to a given
predictor. Negative values specify rejection of nondecreasing splitting
candidates with a given probability, while positive values stipulate a
rejection probability for nonincreasing predictors. A value of zero
indicates that no monotonicity constraint is enforced. Values assigned
to factor predictors are ignored.</p>
<p>The following example rejects nonincreasing predictors as splitting
candidates with probability one:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">regMono =</span> <span class="fu">rep</span>(<span class="fl">1.0</span>, <span class="fu">ncol</span>(x)))</span></code></pre></div>
</div>
<div id="other-training-options" class="section level2">
<h2>Other training options</h2>
<p>Classification training can be fine-tuned by weighting individiual
categories. The option <em>classWeight</em> permits weights to be
specified, by category, for the objective function used to split. This
may be useful, for example, when the training response is
unbalanced.</p>
<p>The following example employs a non-normalized weighting vector to
give the first category twice as much weight as the others. Note that
the category ecoding reflected by ‘levels()’ is not portable:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>       lv <span class="ot">&lt;-</span> <span class="fu">levels</span>(y)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">classWeight =</span> <span class="fu">c</span>(<span class="fl">2.0</span>, <span class="fu">rep</span>(<span class="fl">1.0</span>, <span class="fu">length</span>(lv) <span class="sc">-</span> <span class="dv">1</span>))</span></code></pre></div>
<p>By default, when a numerical predictor is chosen to split a node, the
Arborist assigns its split value as that corresponding to the mean rank,
with respect to the <em>full</em> set of observations on the predictor,
between the two split boundary points. That is, the splitting criterion
attempts to reflect the <em>ECDF</em> of the entire sample. This
contrasts with other implementations, which typically select either the
midpoint value or one of the two boundary values. In particular,
depending upon how the observations are distributed, the midrank can
correspond to a value arbitrarily close to either of the two
boundaries.</p>
<p>The vector <em>splitQuant</em> allows a (sub)quantile value to be
interpolated, so that the split value can be manipulated more finely
with respect to the two endpoints. For example, the following codelet
expresses the default behavior, which is to select the middle rank
(i.e., 0.5 quantile) for all numerical predictors (if any):</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">splitQuant =</span> <span class="fu">rep</span>(<span class="fl">0.5</span>, <span class="fu">ncol</span>(x)))</span></code></pre></div>
<p>Similarly, this example chooses the left endpoint for all relevant
predictors:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(x, y, <span class="at">splitQuant =</span> <span class="fu">rep</span>(<span class="fl">0.0</span>, <span class="fu">ncol</span>(x)))</span></code></pre></div>
</div>
</div>
<div id="preformatting" class="section level1">
<h1>Preformatting</h1>
<p>The Arborist represents predictors internally using a format
streamlined for subsequent training. A “preformatted” representation of
the training data can be generated directly and trained separately as
follows:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>       pf <span class="ot">&lt;-</span> <span class="fu">Preformat</span>(x)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(pf, y)</span></code></pre></div>
<p>Separate preformatting can result in a slight performance improvement
in workflows with iterated training, such as under <em>Caret</em>. This
is simply because the sorting and packing performed at the start of
training can be cached instead of repeatedly computed.</p>
<p>A better motivation for preformatting arises when the training data
can be represented sparsely. Suppose, for example, that <em>B</em> is a
large data set consisting chiefly of predictors with highly repetitive
observation values. As the Arborist is able to identify and compress
repetitive observations, storage might be conserved by first
preformatting <em>B</em>, then deleting it and finally training on the
preformatted representation:</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>       pf <span class="ot">&lt;-</span> <span class="fu">Preformat</span>(B)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">rm</span>(B)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>       rs <span class="ot">&lt;-</span> <span class="fu">Rborist</span>(pf, y)</span></code></pre></div>
</div>
<div id="performance" class="section level1">
<h1>Performance</h1>
<p>Unlike many implementations, which employ sorting to order
observations within a node, the Arborist employs a presort followed by
linear updates. The updates are a form of stable partition, which we
refer to as <em>restaging</em>. Restaging reduces the algorithmic
complexity from the oft-cited <span class="math inline">\(\mathcal{O}(n
\log{}^2 n),\)</span> where <em>n</em> represents the number of training
samples, to <span class="math inline">\(\mathcal{O}(n \log{}
n).\)</span></p>
<p>Restaging is not without its problems, however. As currently
implemented, a double buffer caches outcome data corresponding to every
cell in the design. Hence the restaging containers can grow quite large.
While some users may find this to be acceptable price for scalability,
others may find the storage requirements too high for their application.
Scalability, moreover, may not be an important concern at low sample or
row count.</p>
<p>For high-dimensional problems, the <strong>Ranger</strong> package
may provide a suitable alternative. Similarly, for some problems, the
package <strong>Xgboost</strong> offers excellent storage
characteristics. In the meantime, we envision several improvements, to
appear in upcoming versions, to the Arborist’s parsimony with
storage.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
